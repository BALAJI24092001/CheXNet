{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T05:37:24.732080Z","iopub.execute_input":"2025-03-16T05:37:24.732483Z","iopub.status.idle":"2025-03-16T05:39:12.307591Z","shell.execute_reply.started":"2025-03-16T05:37:24.732455Z","shell.execute_reply":"2025-03-16T05:39:12.306222Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"os.listdir()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport os\n\n\nclass ChestXrayDataSet(Dataset):\n    def __init__(self, data_dir, image_list_file, transform=None):\n        \"\"\"\n        Args:\n            data_dir: path to image directory.\n            image_list_file: path to the file containing images\n                with corresponding labels.\n            transform: optional transform to be applied on a sample.\n        \"\"\"\n        image_names = []\n        labels = []\n        with open(image_list_file, \"r\") as f:\n            for line in f:\n                items = line.split()\n                image_name= items[0]\n                label = items[1:]\n                label = [int(i) for i in label]\n                image_name = os.path.join(data_dir, image_name)\n                image_names.append(image_name)\n                labels.append(label)\n\n        self.image_names = image_names\n        self.labels = labels\n        self.transform = transform\n\n    def __getitem__(self, index):\n        \"\"\"\n        Args:\n            index: the index of item\n\n        Returns:\n            image and its labels\n        \"\"\"\n        image_name = self.image_names[index]\n        image = Image.open(image_name).convert('RGB')\n        label = self.labels[index]\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, torch.FloatTensor(label)\n\n    def __len__(self):\n        return len(self.image_names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}